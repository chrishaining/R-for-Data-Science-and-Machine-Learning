---
title: "Neural Net Project"
output: html_notebook
---

The data consists of 5 columns:

variance of Wavelet Transformed image (continuous)
skewness of Wavelet Transformed image (continuous)
curtosis of Wavelet Transformed image (continuous)
entropy of image (continuous)
class (integer)
Where class indicates whether or not a Bank Note was authentic.

##Â Use read.csv to read the bank_note_data.csv file.
```{r}

library(readr)
df <- read.csv('Training Exercises/Machine Learning Projects/CSV files for ML Projects/bank_note_data.csv')
head(df)

```

```{r}
str(df)
```

# EDA
Create whatever visualizations you are interested in. We'll skip this step for the solutions notebook/video because the data isn't easily interpretable since its just statistical info on images.

## 
```{r}

library(ggplot2)

ggplot(df, aes(x=Image.Var, y=Class)) + geom_point(col='blue', size=4, alpha=0.5)

```

```{r}

ggplot(df, aes(x=Image.Skew, y=Class)) + geom_point(col='blue', size=4, alpha=0.5)

```

```{r}

ggplot(df, aes(x=Image.Curt, y=Class)) + geom_point(col='blue', size=4, alpha=0.5)

```

```{r}

ggplot(df, aes(x=Entropy, y=Class)) + geom_point(col='blue', size=4, alpha=0.5)

```
I'm not sure that the scatterplots tell us much.


# Train Test Split
Use the caTools library to split the data into training and testing sets.
```{r}
library(caTools)
set.seed(101)
split <- sample.split(df$Class, SplitRatio = 0.7)
train <- subset(df, split==T)
test <- subset(df, split==F)
head(train)

```


## Check the structure of the train data and note that Class is still an int data type. We won't convert it to a factor for now because the neural net requires all numeric information
```{r}

str(train)

```

# Build the Neural Net

## Use the neuralnet function to train a neural net, set linear.output=FALSe and choose 10 hidden neurons (hidden=10)
```{r}

library(neuralnet)

nn <- neuralnet(Class ~ Image.Var + Image.Skew + Image.Curt + Entropy,data=train,hidden=10,linear.output=FALSE)

```



# Predictions

```{r}

predicted.nn.values <- compute(nn, test[1:4])
str(predicted.nn.values)

```

```{r}

head(predicted.nn.values$net.result)

```


## Apply the round function to the predicted values so you only 0s and 1s as your predicted classes.
```{r}

predictions <- sapply(predicted.nn.values$net.result,round)
head(predictions)

```

## Use table() to create a confusion matrix of your predictions versus the real values
```{r}

table(predictions,test$Class)

```


# Compare Models

## Call the randomForest library
```{r}
library(randomForest)
```

## Run the Code below to set the Class column of the data as a factor (randomForest needs it to be a factor, not an int like neural nets did. Then re-do the train/test split
```{r}

df$Class <- factor(df$Class)

set.seed(101)
split = sample.split(df$Class, SplitRatio = 0.70)

train = subset(df, split == TRUE)
test = subset(df, split == FALSE)

```

## Create a randomForest model with the new adjusted training data.
```{r}

model <- randomForest(Class ~ Image.Var + Image.Skew + Image.Curt + Entropy,data=train)

```

## Use predict() to get the predicted values from your rf model.
```{r}

rf.pred <- predict(model,test)

```


## Use table() to create the confusion matrix.
```{r}
table(rf.pred,test$Class)
```
It looks like the Neural Net model was better than the randomForest, though they are about the same. 

Thought - we didn't normalise the data in this project. I'm not sure why not.
