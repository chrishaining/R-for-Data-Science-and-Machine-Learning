standardised.iris <- scale(iris[,-5])
#iris[,5]
standardised.iris <- scale(iris[,-5])
var(iris[,2])
var(iris[,4])
#iris[,5]
standardised.iris <- scale(iris[,-5])
var(standardised.iris[,2])
var(standardised.iris[,4])
#iris[,5]
standardised.features <- scale(iris[,-5])
var(standardised.features[,2]) # should be 1
var(standardised.features[,4]) # should be 1
# Join the standardized data with the response/target/label column (the column with the species names)
final.data <- cbind(standardised.features[5])
head(final.data)
#iris[,5]
standardised.features <- scale(iris[,-5])
var(standardised.features[,2]) # should be 1
var(standardised.features[,4]) # should be 1
# Join the standardized data with the response/target/label column (the column with the species names)
final.data <- cbind(standardised.features[5])
head(final.data)
#iris[,5]
standardised.features <- scale(iris[,-5])
var(standardised.features[,2]) # should be 1
var(standardised.features[,4]) # should be 1
# Join the standardized data with the response/target/label column (the column with the species names)
final.data <- cbind(standardised.features,iris[5])
head(final.data)
library(caTools)
# Set a random
set.seed(101)
# Split up the sample, basically randomly assigns a booleans to a new column "sample"
sample <- sample.split(final.data$Species, SplitRatio = 0.70) # SplitRatio = percent of sample==TRUE
# Training Data
train = subset(final.data, sample == TRUE)
# Testing Data
test = subset(final.data, sample == FALSE)
library(caTools)
# Set a random
set.seed(101)
# Split up the sample, basically randomly assigns a booleans to a new column "sample"
sample <- sample.split(final.data$Species, SplitRatio = 0.70) # SplitRatio = percent of sample==TRUE
# Training Data
train = subset(final.data, sample == TRUE)
# Testing Data
test = subset(final.data, sample == FALSE)
head(train)
library(caTools)
# Set a random
set.seed(101)
# Split up the sample, basically randomly assigns a booleans to a new column "sample"
sample <- sample.split(final.data$Species, SplitRatio = 0.70) # SplitRatio = percent of sample==TRUE
# Training Data
train = subset(final.data, sample == TRUE)
# Testing Data
test = subset(final.data, sample == FALSE)
head(test)
library(caTools)
# Set a random
set.seed(101)
# Split up the sample, basically randomly assigns a booleans to a new column "sample"
sample <- sample.split(final.data$Species, SplitRatio = 0.70) # SplitRatio = percent of sample==TRUE
# Training Data
train = subset(final.data, sample == TRUE)
# Testing Data
test = subset(final.data, sample == FALSE)
# Call the class library
library(class)
# Use the knn function to predict Species of the test set. Use k=1
predicted.species <- knn(train,test,train.species,k=1)
# Call the class library
library(class)
# Use the knn function to predict Species of the test set. Use k=1
predicted.species <- knn(train,test,train.Species,k=1)
# Call the class library
library(class)
# Use the knn function to predict Species of the test set. Use k=1
predicted.species <- knn(train,test,train.Species,k=1)
library(caTools)
# Set a random
set.seed(101)
# Split up the sample, basically randomly assigns a booleans to a new column "sample"
sample <- sample.split(final.data$Species, SplitRatio = 0.70) # SplitRatio = percent of sample==TRUE
# Training Data
train = subset(final.data, sample == TRUE)
# Testing Data
test = subset(final.data, sample == FALSE)
head(train)
# Call the class library
library(class)
# Use the knn function to predict Species of the test set. Use k=1
predicted.species <- knn(train,test,train$Species,k=1)
# Call the class library
library(class)
# Use the knn function to predict Species of the test set. Use k=1
predicted.species <- knn(train[1:4],test[1:4],train$Species,k=1)
# Call the class library
library(class)
# Use the knn function to predict Species of the test set. Use k=1
predicted.species <- knn(train[1:4],test[1:4],train$Species,k=1)
head(predicted.species)
# evaluate the model
mean(test$speciee != predicted.species)
# evaluate the model
mean(test$Species != predicted.species)
# evaluate the model
mean(test$Species != predicted.species)
predicted.species <- NULL
error.rate <- NULL
library(ggplot2)
for (i in 1:10) {
set.seed(101)
predicted.species <- knn(train[1:4],test[1:4,train$Species,k=i])
error.rate[i] <- mean(test$Species != predicted.species)
}
# evaluate the model
mean(test$Species != predicted.species)
predicted.species <- NULL
error.rate <- NULL
library(ggplot2)
for (i in 1:10) {
set.seed(101)
predicted.species <- knn(train[1:4],test[1:4,train$Species,k=i])
error.rate[i] <- mean(test$Species != predicted.species)
}
# evaluate the model
mean(test$Species != predicted.species)
predicted.species <- NULL
error.rate <- NULL
library(ggplot2)
for (i in 1:10) {
set.seed(101)
predicted.species <- knn(train[1:4],test[1:4],train$Species,k=i])
# evaluate the model
mean(test$Species != predicted.species)
predicted.species <- NULL
error.rate <- NULL
library(ggplot2)
for (i in 1:10) {
set.seed(101)
predicted.species <- knn(train[1:4],test[1:4],train$Species,k=i)
error.rate[i] <- mean(test$Species != predicted.species)
}
library(ggplot2)
k.values <- 1:10
error.df <- data.frame(error.rate,k.values)
ggplot(error.df,aes(x=k.values,y=error.rate)) + geom_point()
library(ggplot2)
library(plotly)
k.values <- 1:10
error.df <- data.frame(error.rate,k.values)
errs <- ggplot(error.df,aes(x=k.values,y=error.rate)) + geom_point()
ggplotly(errs)
library(ISLR)
library(ISLR)
help(ISLR)
library(ISLR)
head(khan)
library(ISLR)
head(Khan)
library(ISLR)
head(Wage)
library(ISLR)
head(Default)
Default[Default$student=='No'] <- 0
Default$student[Default$student=='No'] <- 0
head(Default)
library(ISLR)
head(Default)
Default$student[Default$student=='No'] <- 0
head(Default)
library(ISLR)
head(Default)
Default$student[Default$student=='No'] <- 0
#head(Default)
library(ISLR)
head(Default)
library(ISLR)
head(Default)
#Default$student[Default$student=='No'] <- 0
#head(Default)
library(ISLR)
head(Default)
library(ISLR)
head(Default)
#Default$student[Default$student=='No'] <- 0
Default$student[Default$student=='Yes'] <- 1
head(Default)
library(ISLR)
head(Default)
# library(ISLR)
# head(Default)
# library(ISLR)
# head(Default)
library(ISLR)
# head(Default)
library(ISLR)
head(Default)
library(ISLR)
head(Credit)
library(ISLR)
# data(Colle)
library(ISLR)
data("College")
library(ISLR)
data("College")
head(College)
library(ISLR)
df <- data("College")
head(df)
library(ISLR)
df <- data("College")
head(df)
library(ISLR)
data("College")
df <= College
head(df)
library(ISLR)
data("College")
df <- College
head(df)
library(ggplot2)
library(ggplot2)
ggplot((df, aes(x=`Room.Board`, y=`Grad.Rate`)) + geom_point()
ggplot(df, aes(x=`Room.Board`, y=`Grad.Rate`)) + geom_point()
ggplot(df, aes(x=`Room.Board`, y=`Grad.Rate`, col=Private)) + geom_point()
ggplot(df, aes(x=`F.Undergrad`, col=Private)) + geom_histogram()
ggplot(df, aes(x=`F.Undergrad`, fill=Private)) + geom_histogram()
ggplot(df, aes(x=`F.Undergrad`, fill=Private)) + geom_histogram(col='black')
ggplot(df, aes(x=`Grad.Rate`, fill=Private)) + geom_histogram(col='black')
library(dplyr)
odd <- df %>% filter(`Grad.Rate`>100)
odd
odd <- df %>% filter(`Grad.Rate`>100)
odd[,1]
odd <- df %>% filter(`Grad.Rate`>100)
odd[1,1]
odd <- df %>% filter(`Grad.Rate`>100)
odd[1,1]
odd <- df %>% filter(`Grad.Rate`>100)
odd[1,]
odd <- df %>% filter(`Grad.Rate`>100)
odd[,1]
odd <- df %>% filter(`Grad.Rate`>100)
odd <- df %>% filter(`Grad.Rate`>100)
df
odd <- df %>% filter(`Grad.Rate`>100)
df[,1]
odd <- df %>% filter(`Grad.Rate`>100)
df[1,]
odd <- df %>% filter(`Grad.Rate`>100)
df[`Grad.Rate`] > 100
odd <- df %>% filter(`Grad.Rate`>100)
df['Grad.Rate'] > 100
odd <- df %>% filter(`Grad.Rate`>100)
oddjob <- df['Grad.Rate'] > 100
odd <- df %>% filter(`Grad.Rate`>100)
oddjob <- df['Grad.Rate'] > 100
oddjob
odd <- df %>% filter(`Grad.Rate`>100)
oddjob <- (df['Grad.Rate'] > 100) == T
oddjob
# odd <- df %>% filter(`Grad.Rate`>100)
# oddjob <- df['Grad.Rate'] > 100
if (df)['Grad.Rate'] > 100) {
# odd <- df %>% filter(`Grad.Rate`>100)
# oddjob <- df['Grad.Rate'] > 100
if (df)['Grad.Rate'] > 100) {
# odd <- df %>% filter(`Grad.Rate`>100)
# oddjob <- df['Grad.Rate'] > 100
if (df['Grad.Rate'] > 100) {
return(df['Grad.Rate'])
}
# odd <- df %>% filter(`Grad.Rate`>100)
# oddjob <- df['Grad.Rate'] > 100
if (df['Grad.Rate'] > 100) {
return(df[,1])
}
# odd <- df %>% filter(`Grad.Rate`>100)
# oddjob <- df['Grad.Rate'] > 100
for col in df {
# odd <- df %>% filter(`Grad.Rate`>100)
# oddjob <- df['Grad.Rate'] > 100
for col in df {
# odd <- df %>% filter(`Grad.Rate`>100)
# oddjob <- df['Grad.Rate'] > 100
for col in df {
# odd <- df %>% filter(`Grad.Rate`>100)
# oddjob <- df['Grad.Rate'] > 100
for (row in df) {
if (`Grad.Rate` > 100) {
return(row)
}
}
# odd <- df %>% filter(`Grad.Rate`>100)
# oddjob <- df['Grad.Rate'] > 100
for (row in df) {
if (row$`Grad.Rate` > 100) {
return(row)
}
}
# odd <- df %>% filter(`Grad.Rate`>100)
# oddjob <- df['Grad.Rate'] > 100
for (row in df) {
if (row[`Grad.Rate`] > 100) {
return(row)
}
}
# odd <- df %>% filter(`Grad.Rate`>100)
# oddjob <- df['Grad.Rate'] > 100
for (row in df) {
if (row['Grad.Rate'] > 100) {
return(row)
}
}
# odd <- df %>% filter(`Grad.Rate`>100)
# oddjob <- df['Grad.Rate'] > 100
for (row in df) {
if ((row['Grad.Rate'] > 100) == ) {
# odd <- df %>% filter(`Grad.Rate`>100)
# oddjob <- df['Grad.Rate'] > 100
for (row in df) {
if ((row['Grad.Rate'] > 100) == T) {
return(row)
}
}
# odd <- df %>% filter(`Grad.Rate`>100)
# oddjob <- df['Grad.Rate'] > 100
for (row in df) {
if ((row['Grad.Rate'] > 100) = T) {
# odd <- df %>% filter(`Grad.Rate`>100)
# oddjob <- df['Grad.Rate'] > 100
for (row in df) {
if ((row['Grad.Rate'] > 100) == T) {
return(row)
}
}
# odd <- df %>% filter(`Grad.Rate`>100)
# oddjob <- df['Grad.Rate'] > 100
subset(df,Grad.Rate > 100)
df['Cazenovia College','Grad.Rate'] <- 100
ggplot(df, aes(x=`Grad.Rate`, fill=Private)) + geom_histogram(col='black')
library(caTools)
# Set a random
set.seed(101)
# Split up the sample, basically randomly assigns a boolean to a new column "sample"
sample <- sample.split(df$Private, SplitRatio = 0.70) # SplitRatio = percent of sample==TRUE
# Training Data
train = subset(df, sample == TRUE)
# Testing Data
test = subset(df, sample == FALSE)
head(train)
# Set a random
set.seed(101)
# Split up the sample, basically randomly assigns a boolean to a new column "sample"
sample <- sample.split(df$Private, SplitRatio = 0.70) # SplitRatio = percent of sample==TRUE
# Training Data
train = subset(df, sample == TRUE)
# Testing Data
test = subset(df, sample == FALSE)
head(train)
head(test)
library(rpart)
privateTree <- rpart(Private ~.,method='class',data = train)
privateTree
plot(privateTree)
ggplot(privateTree)
plot(privateTree)
install.packages("rpart.plot")
library(rpart)
library(rpart.plot)
prp(privateTree)
install.packages("randomForest")
library(rpart)
library(rpart.plot)
library(randomForest)
rf.model <- randomForest(Private ~ ., data=df)
rf.model
rf.model <- randomForest(Private ~ ., data=train)
rf.model
privateTree.predictions <- predict(privateTree, test)
privateTree.predictions
privateTree.predictions <- predict(privateTree, test)
head(privateTree.predictions)
privateTree.predictions <- as.data.frame(privateTree.predictions)
# Lots of ways to do this
joiner <- function(x){
if (x>=0.5){
return('Yes')
}else{
return("No")
}
}
privateTree.predictions$Private <- sapply(privateTree.predictions$Yes,joiner)
head(privateTree.predictions)
table(privateTree.predictions$Private,test$Private)
rf.model <- randomForest(Private ~ ., data=train, importance=TRUE)
rf.model
rf.model$confusion
rf.model$importance
class(rf.model$importance)
imp <- rf.model$importance
imp[order(imp$MeanDecreaseGini)]
imp <- rf.model$importance
imp[order(imp$MeanDecreaseGini),]
imp <- rf.model$importance
imp[order(-imp$MeanDecreaseGini),]
imp <- rf.model$importance
imp[order(-imp['MeanDecreaseGini']),]
imp <- rf.model$importance
imp[order(imp['MeanDecreaseGini']),]
imp <- rf.model$importance
imp[order(imp['MeanDecreaseGini'])]
imp <- rf.model$importance
sort(imp)
p <- predict(rf.model,test)
table(p,test$Private)
install.packages("e1071")
help("svm")
help(svm)
library(ISLR)
head(iris)
library(e1071)
# model is equal to svm function(takes in the column you want to predict ~ the columns used for the prediction, the dataset)
model <- svm(Species ~ ., data = iris)
# model is equal to svm function(takes in the column you want to predict ~ the columns used for the prediction, the dataset)
model <- svm(Species ~ ., data = iris)
model
# model is equal to svm function(takes in the column you want to predict ~ the columns used for the prediction, the dataset)
model <- svm(Species ~ ., data = iris)
summary(model)
tune.results <- tune(svm,train.x = iris[,5],kernel='radial', ranges=list(cost=c(0.1,1,10), gamma=c(0.5,1,2)))
tune.results <- tune(svm,train.x = iris[1:4], train.y = iris[,5],kernel='radial', ranges=list(cost=c(0.1,1,10), gamma=c(0.5,1,2)))
tune.results <- tune(svm,train.x = iris[1:4], train.y = iris[,5],kernel='radial', ranges=list(cost=c(0.1,1,10), gamma=c(0.5,1,2)))
summary(tune.results)
tune.results <- tune(svm,train.x = iris[1:4], train.y = iris[,5],kernel='radial', ranges=list(cost=c(0.1,1,10), gamma=c(0.1,1,2)))
summary(tune.results)
tune.results <- tune(svm,train.x = iris[1:4], train.y = iris[,5],kernel='radial', ranges=list(cost=c(0.1,1.5,10), gamma=c(0.1,1,2)))
summary(tune.results)
tuned.svm <- svm(Species ~ ., data=iris, kernel='radial', cost=1.5, gamma=0.5)
tuned.svm <- svm(Species ~ ., data=iris, kernel='radial', cost=1.5, gamma=0.5)
summary(tuned.svm)
tuned.svm <- svm(Species ~ ., data=iris, kernel='radial', cost=1.5, gamma=0.1)
summary(tuned.svm)
library(ggplot2)
library(e1071)
library(readr)
loans <- read.csv('Training Exercises/Machine Learning Projects/CSV files for ML Projects/loan_data.csv')
head(loans)
str(loans)
summary(loans)
loans <- loans <- mutate(`inq.last.6mths`=factor(`inq.last.6mths`), `delinq.2yrs`=factor(`delinq.2yrs`), `pub.rec`=factor(`pub.rec`), `not.fully.paid`=factor(`not.fully.paid`), `credit.policy`=factor(`credit.policy`))
library(ggplot2)
library(e1071)
library(readr)
library(dplyr)
loans <- loans <- mutate(`inq.last.6mths`=factor(`inq.last.6mths`), `delinq.2yrs`=factor(`delinq.2yrs`), `pub.rec`=factor(`pub.rec`), `not.fully.paid`=factor(`not.fully.paid`), `credit.policy`=factor(`credit.policy`))
library(ggplot2)
library(e1071)
library(readr)
library(dplyr)
loans <- read.csv('Training Exercises/Machine Learning Projects/CSV files for ML Projects/loan_data.csv')
head(loans)
str(loans)
summary(loans)
loans <- loans <- mutate(`inq.last.6mths`=factor(`inq.last.6mths`), `delinq.2yrs`=factor(`delinq.2yrs`), `pub.rec`=factor(`pub.rec`), `not.fully.paid`=factor(`not.fully.paid`), `credit.policy`=factor(`credit.policy`))
loans <- loans <- mutate(inq.last.6mths=factor(inq.last.6mths), `delinq.2yrs`=factor(`delinq.2yrs`), `pub.rec`=factor(`pub.rec`), `not.fully.paid`=factor(`not.fully.paid`), `credit.policy`=factor(`credit.policy`))
loans <- loans <- mutate(`inq.last.6mths`=factor(`inq.last.6mths`), `delinq.2yrs`=factor(`delinq.2yrs`), `pub.rec`=factor(`pub.rec`), `not.fully.paid`=factor(`not.fully.paid`), `credit.policy`=factor(`credit.policy`))
loans <- loans %>% mutate(`inq.last.6mths`=factor(`inq.last.6mths`), `delinq.2yrs`=factor(`delinq.2yrs`), `pub.rec`=factor(`pub.rec`), `not.fully.paid`=factor(`not.fully.paid`), `credit.policy`=factor(`credit.policy`))
head(loans)
ggplot(loans, aes(x=fico)) + geom_histogram(aes(col=`not.fully.paid`))
ggplot(loans, aes(x=fico)) + geom_histogram(aes(fill=`not.fully.paid`), col='black')
ggplot(loans, aes(x=purpose)) + geom_bar(aes(fill=`not.fully.paid`), col='black', position='dodge')
ggplot(loans, aes(x=purpose)) + geom_bar(aes(fill=`not.fully.paid`), col='black', position='dodge') + theme(axis.text.x = element_text(angle = 90, hjust = 1))
ggplot(loans, aes(x=fico, y=`int.rate`)) + geom_point(aes(col=`not.fully.paid`))
ggplot(loans, aes(x=fico, y=`int.rate`)) + geom_point(aes(col=`not.fully.paid`), alpha=0.5)
ggplot(loans, aes(x=fico, y=`int.rate`)) + geom_point(aes(col=`not.fully.paid`), alpha=0.5) + + scale_fill_manual(values = c('green','red')) + theme_bw()
ggplot(loans, aes(x=fico, y=`int.rate`)) + geom_point(aes(col=`not.fully.paid`), alpha=0.5) + scale_fill_manual(values = c('green','red')) + theme_bw()
ggplot(loans, aes(x=fico, y=`int.rate`)) + geom_point(alpha=0.5) + scale_fill_manual(values = c('green','red')) + theme_bw()
ggplot(loans, aes(x=fico, y=`int.rate`)) + geom_point(aes(col=`not.fully.paid`), alpha=0.5) + scale_fill_manual(values = c('green','red'))
ggplot(loans, aes(x=fico, y=`int.rate`)) + geom_point(alpha=0.5) + scale_fill_manual(values = c('green','red'))
ggplot(loans, aes(x=fico, y=`int.rate`)) + geom_point(aes(col=`not.fully.paid`), alpha=0.5) + scale_fill_manual(values = c('green','red'))
library(ggplot2)
library(e1071)
library(readr)
library(dplyr)
library(caTools)
set.seed(101)
spl = sample.split(loans$not.fully.paid, 0.7)
train = subset(loans, spl == TRUE)
test = subset(loans, spl == FALSE)
model <- svm(not.fully.pad ~ ., data = train)
model <- svm(not.fully.paid ~ ., data = train)
summary(model)
predicted.values <- predict(model,test[1:13])
predicted.values <- predict(model,test[1:13])
table(predicted.values,test$not.fully.paid)
tune.results <- tune(svm,train.x=not.fully.paid~., data=train,kernel='radial',
ranges=list(cost=c(1, 10), gamma=c(0.1, 0.5, 1)))
tune.results <- tune(svm,train.x=not.fully.paid~., data=train,kernel='radial',
ranges=list(cost=c(1, 10), gamma=c(0.1, 1)))
summary(tune.results)
tune.results <- tune(svm,train.x=not.fully.paid~., data=train,kernel='radial',
ranges=list(cost=c(1, 10), gamma=c(0.1, 10)))
summary(tune.results)
ggplot(loans, aes(x=fico)) + geom_histogram(aes(fill=`not.fully.paid`), col='black') + scale_fill_manual(values = c('green','red'))
ggplot(loans, aes(x=purpose)) + geom_bar(aes(fill=`not.fully.paid`), col='black', position='dodge') + scale_fill_manual(values = c('green','red')) + theme(axis.text.x = element_text(angle = 90, hjust = 1))
ggplot(loans, aes(x=fico, y=`int.rate`)) + geom_point(aes(col=`not.fully.paid`), alpha=0.5) + scale_fill_manual(values = c('green','red'))
tune.results <- tune(svm,train.x=not.fully.paid~., data=train,kernel='radial',
ranges=list(cost=c(1, 10), gamma=c(0.1, 1)))
